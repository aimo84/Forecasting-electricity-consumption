{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mape of GRA_GRU is: 0.1353879100119654\n",
      "The variance of GRA_GRU is: 0.008405628814192028\n",
      "The variance of GRU is: 0.006925953144872238\n",
      "The variance of LE_GRA: 0.01259354709982402\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from math import *\n",
    "import math\n",
    "from sympy import *\n",
    "from sympy.abc import x,y,z,a,b,c,d\n",
    "import numpy as np\n",
    "import numpy\n",
    "import csv\n",
    "#F \n",
    "\n",
    "def preprocessing(before_filename, after_filename):\n",
    "    train_dataset = read_csv(before_filename, header=0, index_col=None)\n",
    "    train_values = train_dataset.values\n",
    "\n",
    "    power = train_values[:, 0]\n",
    "    temperature = train_values[:, 1]\n",
    "    humidity = train_values[:, 2]\n",
    "    speed = train_values[:, 3]\n",
    "    common = [1 for i in range(power.shape[0])]\n",
    "\n",
    "    transfer_power = []\n",
    "    transfer_temperature = []\n",
    "    transfer_humidity = []\n",
    "    transfer_speed = []\n",
    "\n",
    "    except_value = -5.0\n",
    "\n",
    "    for index in range(len(power)):\n",
    "        if round(log(power[index], e), 2) == -inf:\n",
    "            transfer_power.append(except_value)\n",
    "        else:\n",
    "            transfer_power.append(round(log(power[index], e), 2))\n",
    "\n",
    "    for index in range(len(temperature)):\n",
    "        if round(log(temperature[index], e), 2) == -inf:\n",
    "            transfer_temperature.append(except_value)\n",
    "        else:\n",
    "            transfer_temperature.append(round(log(temperature[index], e), 2))\n",
    "\n",
    "    for index in range(len(humidity)):\n",
    "        if round(log(humidity[index], e), 2) == -inf:\n",
    "            transfer_humidity.append(except_value)\n",
    "        else:\n",
    "            transfer_humidity.append(round(log(humidity[index], e), 2))\n",
    "\n",
    "    for index in range(len(speed)):\n",
    "        if round(log(speed[index], e), 2) == -inf:\n",
    "            transfer_speed.append(except_value)\n",
    "        else:\n",
    "            transfer_speed.append(round(log(speed[index], e), 2))\n",
    "\n",
    "    transfer_common = numpy.array(common)\n",
    "\n",
    "    Data = {'power': transfer_power, 'temperature': transfer_temperature, 'humidity': transfer_humidity,\n",
    "            'speed': transfer_speed, 'common': transfer_common}\n",
    "    df = DataFrame(Data, columns=['power', 'temperature', 'humidity', 'speed', 'common'])\n",
    "    df.to_csv(after_filename, index=False)\n",
    "\n",
    "#验证集的MAPE\n",
    "def val_start(test_filename, n):\n",
    "    dt = read_csv(test_filename, header=0, index_col=False)\n",
    "    df = pd.DataFrame(dt)\n",
    "    para = para_median(n)\n",
    "    mape = 0\n",
    "    #print(para)\n",
    "    for index in range(len(df.values)):\n",
    "        X = df.values[index][1:]\n",
    "        testY = df.values[index][0]\n",
    "        para = np.array(para).reshape(4, 1)\n",
    "        predict = np.dot(X, para)\n",
    "        mape = mape + abs(pow(e,testY)-pow(e,predict))/pow(e,testY)\n",
    "   \n",
    "    return mape/len(df.values)\n",
    "   \n",
    "#取前n个最优解参数的中位数\n",
    "def para_median(n):\n",
    "    lc = pd.DataFrame(pd.read_csv('Xe1_A.csv', header=None, names=['xulie', 'wucha']))#Xe1_A.csv,Xe1_B.csv...Xe1_F.csv\n",
    "    tdd = lc.sort_values(by='wucha', ascending=True).head(n)\n",
    "    index = list(tdd['xulie'])\n",
    "    dt = pd.read_csv('Xee_A.csv', header=None, names=['xulie', '参数1', '参数2', '参数3', '参数4'])#Xee_A.csv,Xee_B.csv...Xee_F.csv\n",
    "    df = pd.DataFrame(dt)\n",
    "    X = []\n",
    "    for i in index:\n",
    "        X.append([df.values[i][1],df.values[i][2],df.values[i][3],df.values[i][4]])\n",
    "    X = np.array(X)\n",
    "    para1 = np.median(X[:, 0])\n",
    "    para2 = np.median(X[:, 1])\n",
    "    para3 = np.median(X[:, 2])\n",
    "    para4 = np.median(X[:, 3])\n",
    "    return [para1, para2, para3, para4]\n",
    "\n",
    "#write the mape，accurary of LE_GRA to .csv file\n",
    "def lr_mape_csv(filename3_test,n):\n",
    "    mape = []\n",
    "    for index in range(1, n):\n",
    "        mape.append(val_start(filename3_test, index))\n",
    "\n",
    "    min_index = mape.index(min(mape))\n",
    "    #print(para_median(min_index))\n",
    "\n",
    "    dt = read_csv(filename3_test, header=0, index_col=False)\n",
    "    df = pd.DataFrame(dt)\n",
    "    mape1 = 0\n",
    "    #print(para)\n",
    "    para = para_median(min_index + 1)\n",
    "    predict_Y = []\n",
    "    reality_Y = []\n",
    "    mp = []\n",
    "    acc = []\n",
    "    for index in range(len(df.values)):\n",
    "        X = df.values[index][1:]\n",
    "        testY = df.values[index][0]\n",
    "        reality_Y.append(pow(e,testY))\n",
    "        para = np.array(para).reshape(4, 1)\n",
    "        predict = np.dot(X, para)\n",
    "        predict_Y.append(pow(e,predict))\n",
    "        mape1 = mape1 + abs(pow(e,testY)-pow(e,predict))/pow(e,testY)\n",
    "        mp.append(abs(pow(e,testY)-pow(e,predict))/pow(e,testY))\n",
    "        acc.append(1-abs(pow(e,testY)-pow(e,predict))/pow(e,testY))\n",
    "    Data = {'reality': reality_Y, 'predict': predict_Y, 'mape': mp, 'accurary': acc}\n",
    "    df = DataFrame(Data, columns=[\"reality\", \"predict\", \"mape\", \"accurary\"])\n",
    "    df.to_csv(\"experimentA_LE_validation_result.csv\", index=False)#experimentA_LE_validation_result.csv...experimentF_LE_validation_result.csv\n",
    "\n",
    "#GRU模型的信息熵\n",
    "def Entropy_GRU(filename3_gru_result):\n",
    "    dt = read_csv(filename3_gru_result, header=0, index_col=False)\n",
    "    df = pd.DataFrame(dt)\n",
    "\n",
    "    mape = df.values[0:,2]\n",
    "    n = len(mape)\n",
    "    acc = []\n",
    "    for index in range(n):\n",
    "        acc.append(1-mape[index])\n",
    "\n",
    "    P_GRU = []\n",
    "    for index in range(n):\n",
    "        P_GRU.append(acc[index]/sum(acc))\n",
    "    P = 0\n",
    "    for index in range(n):\n",
    "        if P_GRU[index]<=0:\n",
    "            continue\n",
    "        else:\n",
    "            P = P + P_GRU[index] * math.log(P_GRU[index],e)\n",
    "    entropy_gru = - math.log(n,e) * P\n",
    "    return entropy_gru\n",
    "\n",
    "#LR模型的信息熵\n",
    "def Entropy_LR(filename3_lr_result):\n",
    "    dt = read_csv(filename3_lr_result, header=0, index_col=False)\n",
    "    df = pd.DataFrame(dt)\n",
    "    acc = df.values[0:, 3]\n",
    "    n = len(acc)\n",
    "\n",
    "\n",
    "    P_LR = []\n",
    "    for index in range(n):\n",
    "        P_LR.append(acc[index]/sum(acc))\n",
    "    P = 0\n",
    "    for index in range(n):\n",
    "        if P_LR[index]<=0:\n",
    "            continue\n",
    "        else:\n",
    "            P = P + P_LR[index] * math.log(P_LR[index],e)\n",
    "    entropy_lr = -math.log(n,e) * P\n",
    "    return entropy_lr\n",
    "\n",
    "#GRU模型和LR模型分别的权重W_GRU,W_LR\n",
    "def weight(filename3_gru_result,filename3_lr_result):\n",
    "    entropy_gru = Entropy_GRU(filename3_gru_result)\n",
    "    entropy_lr  = Entropy_LR(filename3_lr_result)\n",
    "    W_GRU = (1 - entropy_gru)/(2 - (entropy_gru + entropy_lr))\n",
    "    W_LR  = (1 - entropy_lr)/(2 -(entropy_gru + entropy_lr))\n",
    "    return W_GRU, W_LR\n",
    "\n",
    "\n",
    "acc_gru_lr = []\n",
    "\n",
    "#混合模型的mape和准确率的方差\n",
    "def ensemble_mape_var(filename3_gru_result,filename3_lr_result,filename3_reality,filename3_gru_r_result,filename3_lr_r_result):\n",
    "    W_GRU,W_LR = weight(filename3_gru_result,filename3_lr_result)\n",
    "    dt_lr = read_csv(filename3_lr_r_result, header=0, index_col=False)\n",
    "    df_lr = pd.DataFrame(dt_lr)\n",
    "    dt_gru = read_csv(filename3_gru_r_result, header=0, index_col=False)\n",
    "    df_gru = pd.DataFrame(dt_gru)\n",
    "    dt_test = read_csv(filename3_reality, header=0, index_col=False)\n",
    "    df_test = pd.DataFrame(dt_test)\n",
    "    n = len(df_test.values)\n",
    "    mape = 0\n",
    "    for index in range(n):\n",
    "        predict = W_GRU * df_gru.values[index][1] + W_LR * df_lr.values[index][1]\n",
    "        mape = mape + abs(df_test.values[index][0] - predict)/df_test.values[index][0]\n",
    "        if abs(df_test.values[index][0] - predict)/df_test.values[index][0]<=1:\n",
    "            acc_gru_lr.append(1-abs(df_test.values[index][0] - predict)/df_test.values[index][0])\n",
    "    print(\"The mape of GRA_GRU is:\", mape/n)\n",
    "    print(\"The variance of GRA_GRU is:\", np.var(acc_gru_lr))\n",
    "\n",
    "\n",
    "\n",
    "#GRU模型准确率的方差\n",
    "def gru_variance(filename3_gru_result):\n",
    "    dt_gru = read_csv(filename3_gru_result, header=0, index_col=False)\n",
    "    df_gru = pd.DataFrame(dt_gru)\n",
    "    mape_gru = df_gru.values[0:, 2]\n",
    "    n_gru = len(mape_gru)\n",
    "    acc_gru = []\n",
    "    for index in range(n_gru):\n",
    "        if mape_gru[index] <= 1:\n",
    "            acc_gru.append(1 - mape_gru[index])\n",
    "    print(\"The variance of GRU is:\", np.var(acc_gru))\n",
    "\n",
    "#LR模型准确率的方差\n",
    "def lr_variance(filename3_lr_result):\n",
    "    dt_lr = read_csv(filename3_lr_result, header=0, index_col=False)\n",
    "    df_lr = pd.DataFrame(dt_lr)\n",
    "    mape_lr = df_lr.values[0:, 3]\n",
    "    n_lr = len(mape_lr)\n",
    "    acc_lr = []\n",
    "    for index in range(n_lr):\n",
    "        if mape_lr[index] >= 0:\n",
    "            acc_lr.append(mape_lr)\n",
    "    print(\"The variance of LE_GRA:\", np.var(acc_lr))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "#   preprocessing(\"validationA.csv\", \"valA.csv\")#validationA.csv/valA.csv...validationF.csv/valF.csv\n",
    "#   val_start(\"valA.csv\",150)  #valA...valF\n",
    "    lr_mape_csv(\"valA.csv\", 150) #product experimentF_LE_validation_result.csv  #valA...valF\n",
    "    ensemble_mape_var(\"experimentA_GRU_validation_result.csv\", \"experimentA_LE_validation_result.csv\", \"testingA.csv\",\"experimentA_GRU_result.csv\",\"experimentA_LE_result.csv\")#\"experimentA_GRU_validation_result.csv\", \"experimentA_LE_validation_result.csv\", \"testingA.csv\",\"experimentA_GRU_result.csv\",\"experimentA_LE_result.csv\"...\"experimentA_GRU_validation_result.csv\", \"experimentA_LE_validation_result.csv\", \"testingA.csv\",\"experimentA_GRU_result.csv\",\"experimentA_LE_result.csv\"\n",
    "    gru_variance(\"experimentA_GRU_result.csv\")#experimentA_GRU_result.csv...experimentF_GRU_result.csv\n",
    "    lr_variance(\"experimentA_LE_result.csv\")#experimentA_LE_result.csv...experimentF_LE_result.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
