{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,classification_report,confusion_matrix\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import csv\n",
    "\n",
    "training22=pd.read_csv(\"trainingA.csv\")\n",
    "testing1=pd.read_csv(\"testingA.csv\")\n",
    "\n",
    "\n",
    "training20=pd.read_csv(\"trainingB.csv\")\n",
    "testing2=pd.read_csv(\"testingB.csv\")\n",
    "\n",
    "training18=pd.read_csv(\"trainingC.csv\")\n",
    "testing3=pd.read_csv(\"testingC.csv\")\n",
    "\n",
    "training16=pd.read_csv(\"trainingD.csv\")\n",
    "testing4=pd.read_csv(\"testingD.csv\")\n",
    "\n",
    "training14=pd.read_csv(\"trainingE.csv\")\n",
    "testing5=pd.read_csv(\"testingE.csv\")\n",
    "\n",
    "training12=pd.read_csv(\"trainingF.csv\")\n",
    "testing6=pd.read_csv(\"testingF.csv\")\n",
    "\n",
    "\n",
    "\n",
    "training22_features=training22.loc[:,'temperature':'speed']\n",
    "training22_label=training22.loc[:,'power']\n",
    "testing1_features=testing1.loc[:,'temperature':'speed']\n",
    "testing1_label=testing1.loc[:,'power']\n",
    "\n",
    "\n",
    "training20_features=training20.loc[:,'temperature':'speed']\n",
    "training20_label=training20.loc[:,'power']\n",
    "testing2_features=testing2.loc[:,'temperature':'speed']\n",
    "testing2_label=testing2.loc[:,'power']\n",
    "\n",
    "training18_features=training18.loc[:,'temperature':'speed']\n",
    "training18_label=training18.loc[:,'power']\n",
    "testing3_features=testing3.loc[:,'temperature':'speed']\n",
    "testing3_label=testing3.loc[:,'power']\n",
    "\n",
    "training16_features=training16.loc[:,'temperature':'speed']\n",
    "training16_label=training16.loc[:,'power']\n",
    "testing4_features=testing4.loc[:,'temperature':'speed']\n",
    "testing4_label=testing4.loc[:,'power']\n",
    "\n",
    "training14_features=training14.loc[:,'temperature':'speed']\n",
    "training14_label=training14.loc[:,'power']\n",
    "testing5_features=testing5.loc[:,'temperature':'speed']\n",
    "testing5_label=testing5.loc[:,'power']\n",
    "\n",
    "training12_features=training12.loc[:,'temperature':'speed']\n",
    "training12_label=training12.loc[:,'power']\n",
    "testing6_features=testing6.loc[:,'temperature':'speed']\n",
    "testing6_label=testing6.loc[:,'power']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance upon 1-month testing data: 0.012989717283793117\n",
      "MAPE upon 1-month testing data: 0.1939108780613108\n",
      "variance upon 2-month testing data: 0.010176394004139794\n",
      "MAPE upon 2-month testing data: 0.3885600809483352\n",
      "variance upon 3-month testing data: 0.01622905351782674\n",
      "MAPE upon 3-month testing data: 0.21187417910388037\n",
      "variance upon 4-month testing data: 0.01901341247025951\n",
      "MAPE upon 4-month testing data: 0.29500049916017984\n",
      "variance upon 5-month testing data: 0.02199573166998113\n",
      "MAPE upon 5-month testing data: 0.2164993761897349\n",
      "variance upon 6-month testing data: 0.016934356352626818\n",
      "MAPE upon 6-month testing data: 0.2058899841620048\n"
     ]
    }
   ],
   "source": [
    "#ordinary Least Squares regression\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn import linear_model\n",
    "from sklearn.utils.validation import check_array as check_arrays\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    #y_true, y_pred = check_arrays(y_true, y_pred)\n",
    "    return np.abs((y_true - y_pred) / y_true)\n",
    "def mape(n,label,prediction): \n",
    "    j=0\n",
    "    for i in range(0,n,1):\n",
    "        mapen=mean_absolute_percentage_error(label[i],prediction[i])\n",
    "        j=j+mapen\n",
    "    return j/n\n",
    "def variance(n,label,prediction): \n",
    "    j=0\n",
    "    transfer_power = []\n",
    "    for i in range(0,n,1):\n",
    "        mapen=mean_absolute_percentage_error(label[i],prediction[i])\n",
    "        transfer_power.append(mapen)\n",
    "    return np.var(transfer_power)\n",
    "#\n",
    "reg_training22=linear_model.LinearRegression(fit_intercept=True, normalize=False, copy_X=True, n_jobs=None).fit(training22_features,training22_label)\n",
    "prediction_testing1=reg_training22.predict(testing1_features)\n",
    "n1=testing1_label.shape[0]\n",
    "label1=testing1_label\n",
    "prediction1=prediction_testing1\n",
    "mape1=mape(n1,label1,prediction1)\n",
    "variance1=variance(n1,label1,prediction1)\n",
    "print(\"variance upon 1-month testing data:\",variance1)\n",
    "print(\"MAPE upon 1-month testing data:\",mape1)\n",
    "\n",
    "reg_training20=linear_model.LinearRegression(fit_intercept=True, normalize=False, copy_X=True, n_jobs=None).fit(training20_features,training20_label)\n",
    "prediction_testing2=reg_training20.predict(testing2_features)\n",
    "n2=testing2_label.shape[0]\n",
    "label2=testing2_label\n",
    "prediction2=prediction_testing2\n",
    "mape2=mape(n2,label2,prediction2)\n",
    "variance2=variance(n2,label2,prediction2)\n",
    "print(\"variance upon 2-month testing data:\",variance2)\n",
    "print(\"MAPE upon 2-month testing data:\",mape2)\n",
    "\n",
    "reg_training18=linear_model.LinearRegression(fit_intercept=True, normalize=False, copy_X=True, n_jobs=None).fit(training18_features,training18_label)\n",
    "prediction_testing3=reg_training18.predict(testing3_features)\n",
    "n3=testing3_label.shape[0]\n",
    "label3=testing3_label\n",
    "prediction3=prediction_testing3\n",
    "mape3=mape(n3,label3,prediction3)\n",
    "variance3=variance(n3,label3,prediction3)\n",
    "print(\"variance upon 3-month testing data:\",variance3)\n",
    "print(\"MAPE upon 3-month testing data:\",mape3)\n",
    "\n",
    "\n",
    "\n",
    "reg_training16=linear_model.LinearRegression(fit_intercept=True, normalize=False, copy_X=True, n_jobs=None).fit(training16_features,training16_label)\n",
    "prediction_testing4=reg_training16.predict(testing4_features)\n",
    "n4=testing4_label.shape[0]\n",
    "label4=testing4_label\n",
    "prediction4=prediction_testing4\n",
    "mape4=mape(n4,label4,prediction4)\n",
    "variance4=variance(n4,label4,prediction4)\n",
    "print(\"variance upon 4-month testing data:\",variance4)\n",
    "print(\"MAPE upon 4-month testing data:\",mape4)\n",
    "\n",
    "reg_training14=linear_model.LinearRegression(fit_intercept=True, normalize=False, copy_X=True, n_jobs=None).fit(training14_features,training14_label)\n",
    "prediction_testing5=reg_training14.predict(testing5_features)\n",
    "n5=testing5_label.shape[0]\n",
    "label5=testing5_label\n",
    "prediction5=prediction_testing5\n",
    "mape5=mape(n5,label5,prediction5)\n",
    "variance5=variance(n5,label5,prediction5)\n",
    "print(\"variance upon 5-month testing data:\",variance5)\n",
    "print(\"MAPE upon 5-month testing data:\",mape5)\n",
    "\n",
    "reg_training12=linear_model.LinearRegression(fit_intercept=True, normalize=False, copy_X=True, n_jobs=None).fit(training12_features,training12_label)\n",
    "prediction_testing6=reg_training12.predict(testing6_features)\n",
    "n6=testing6_label.shape[0]\n",
    "label6=testing6_label\n",
    "prediction6=prediction_testing6\n",
    "mape6=mape(n6,label6,prediction6)\n",
    "variance6=variance(n6,label6,prediction6)\n",
    "print(\"variance upon 6-month testing data:\",variance6)\n",
    "print(\"MAPE upon 6-month testing data:\",mape6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance upon 1-month testing data: 0.01250930395231607\n",
      "MAPE upon 1-month testing data: 0.2795318645720583\n",
      "variance upon 2-month testing data: 0.008807320375051766\n",
      "MAPE upon 2-month testing data: 0.4102186289161821\n",
      "variance upon 3-month testing data: 0.014745044678857367\n",
      "MAPE upon 3-month testing data: 0.22863840269712254\n",
      "variance upon 4-month testing data: 0.020772135656721216\n",
      "MAPE upon 4-month testing data: 0.299130753748309\n",
      "variance upon 5-month testing data: 0.01854985486294433\n",
      "MAPE upon 5-month testing data: 0.19027019059246666\n",
      "variance upon 6-month testing data: 0.015000939437898136\n",
      "MAPE upon 6-month testing data: 0.19184283317644935\n"
     ]
    }
   ],
   "source": [
    "#svr\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn import svm\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return np.abs((y_true - y_pred) / y_true)\n",
    "def mape(n,label,prediction): \n",
    "    j=0\n",
    "    for i in range(0,n,1):\n",
    "        mapen=mean_absolute_percentage_error(label[i],prediction[i])\n",
    "        j=j+mapen\n",
    "    return j/n\n",
    "def variance(n,label,prediction): \n",
    "    j=0\n",
    "    transfer_power = []\n",
    "    for i in range(0,n,1):\n",
    "        mapen=mean_absolute_percentage_error(label[i],prediction[i])\n",
    "        transfer_power.append(mapen)\n",
    "    return np.var(transfer_power)\n",
    "#\n",
    "reg_training22=svm.SVR(kernel='rbf', gamma=5/12, C=1.1).fit(training22_features,training22_label)\n",
    "prediction_testing1=reg_training22.predict(testing1_features)\n",
    "n1=testing1_label.shape[0]\n",
    "label1=testing1_label\n",
    "prediction1=prediction_testing1\n",
    "mape1=mape(n1,label1,prediction1)\n",
    "variance1=variance(n1,label1,prediction1)\n",
    "print(\"variance upon 1-month testing data:\",variance1)\n",
    "print(\"MAPE upon 1-month testing data:\",mape1)\n",
    "\n",
    "\n",
    "reg_training20=svm.SVR(kernel='rbf', gamma=1/2,C=1.0).fit(training20_features,training20_label)\n",
    "prediction_testing2=reg_training20.predict(testing2_features)\n",
    "n2=testing2_label.shape[0]\n",
    "label2=testing2_label\n",
    "prediction2=prediction_testing2\n",
    "mape2=mape(n2,label2,prediction2)\n",
    "variance2=variance(n2,label2,prediction2)\n",
    "print(\"variance upon 2-month testing data:\",variance2)\n",
    "print(\"MAPE upon 2-month testing data:\",mape2)\n",
    "\n",
    "\n",
    "reg_training18=svm.SVR(kernel='rbf', gamma=4/5, C=1.1).fit(training18_features,training18_label)\n",
    "prediction_testing3=reg_training18.predict(testing3_features)\n",
    "n3=testing3_label.shape[0]\n",
    "label3=testing3_label\n",
    "prediction3=prediction_testing3\n",
    "mape3=mape(n3,label3,prediction3)\n",
    "variance3=variance(n3,label3,prediction3)\n",
    "print(\"variance upon 3-month testing data:\",variance3)\n",
    "print(\"MAPE upon 3-month testing data:\",mape3)\n",
    "\n",
    "reg_training16=svm.SVR(kernel='rbf', gamma=1/2, C=1.5).fit(training16_features,training16_label)\n",
    "prediction_testing4=reg_training16.predict(testing4_features)\n",
    "n4=testing4_label.shape[0]\n",
    "label4=testing4_label\n",
    "prediction4=prediction_testing4\n",
    "mape4=mape(n4,label4,prediction4)\n",
    "variance4=variance(n4,label4,prediction4)\n",
    "print(\"variance upon 4-month testing data:\",variance4)\n",
    "print(\"MAPE upon 4-month testing data:\",mape4)\n",
    "\n",
    "reg_training14=svm.SVR(kernel='rbf', gamma=4/5, C=5).fit(training14_features,training14_label)\n",
    "prediction_testing5=reg_training14.predict(testing5_features)\n",
    "n5=testing5_label.shape[0]\n",
    "label5=testing5_label\n",
    "prediction5=prediction_testing5\n",
    "mape5=mape(n5,label5,prediction5)\n",
    "variance5=variance(n5,label5,prediction5)\n",
    "print(\"variance upon 5-month testing data:\",variance5)\n",
    "print(\"MAPE upon 5-month testing data:\",mape5)\n",
    "\n",
    "reg_training12=svm.SVR(kernel='rbf', gamma=4/5, C=5).fit(training12_features,training12_label)\n",
    "prediction_testing6=reg_training12.predict(testing6_features)\n",
    "n6=testing6_label.shape[0]\n",
    "label6=testing6_label\n",
    "prediction6=prediction_testing6\n",
    "mape6=mape(n6,label6,prediction6)\n",
    "variance6=variance(n6,label6,prediction6)\n",
    "print(\"variance upon 6-month testing data:\",variance6)\n",
    "print(\"MAPE upon 6-month testing data:\",mape6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance upon 1-month testing data: 0.012991498331682068\n",
      "MAPE upon 1-month testing data: 0.1939510943002982\n",
      "variance upon 2-month testing data: 0.01017357198179355\n",
      "MAPE upon 2-month testing data: 0.3885520420261209\n",
      "variance upon 3-month testing data: 0.016227439827562872\n",
      "MAPE upon 3-month testing data: 0.2119026215038419\n",
      "variance upon 4-month testing data: 0.01901367215915927\n",
      "MAPE upon 4-month testing data: 0.29498001355016157\n",
      "variance upon 5-month testing data: 0.021994089311684704\n",
      "MAPE upon 5-month testing data: 0.21651797129595537\n",
      "variance upon 6-month testing data: 0.016934603384556254\n",
      "MAPE upon 6-month testing data: 0.2058941676812731\n"
     ]
    }
   ],
   "source": [
    "#Bayesian Ridge Regression\n",
    "from  sklearn import linear_model\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    #y_true, y_pred = check_arrays(y_true, y_pred)\n",
    "    return np.abs((y_true - y_pred) / y_true)\n",
    "def mape(n,label,prediction): \n",
    "    j=0\n",
    "    for i in range(0,n,1):\n",
    "        mapen=mean_absolute_percentage_error(label[i],prediction[i])\n",
    "        j=j+mapen\n",
    "    return j/n\n",
    "def variance(n,label,prediction): \n",
    "    j=0\n",
    "    transfer_power = []\n",
    "    for i in range(0,n,1):\n",
    "        mapen=mean_absolute_percentage_error(label[i],prediction[i])\n",
    "        transfer_power.append(mapen)\n",
    "    return np.var(transfer_power)\n",
    "#\n",
    "reg_training22=linear_model.BayesianRidge(n_iter=350, tol=0.001, alpha_1=1e-06, alpha_2=1e-06, lambda_1=1e-06, lambda_2=1e-06).fit(training22_features,training22_label)\n",
    "prediction_testing1=reg_training22.predict(testing1_features)\n",
    "n1=testing1_label.shape[0]\n",
    "label1=testing1_label\n",
    "prediction1=prediction_testing1\n",
    "mape1=mape(n1,label1,prediction1)\n",
    "variance1=variance(n1,label1,prediction1)\n",
    "print(\"variance upon 1-month testing data:\",variance1)\n",
    "print(\"MAPE upon 1-month testing data:\",mape1)\n",
    "\n",
    "reg_training20=linear_model.BayesianRidge(n_iter=350, tol=0.001, alpha_1=1e-06, alpha_2=1e-06, lambda_1=1e-06, lambda_2=1e-06).fit(training20_features,training20_label)\n",
    "prediction_testing2=reg_training20.predict(testing2_features)\n",
    "n2=testing2_label.shape[0]\n",
    "label2=testing2_label\n",
    "prediction2=prediction_testing2\n",
    "mape2=mape(n2,label2,prediction2)\n",
    "variance2=variance(n2,label2,prediction2)\n",
    "print(\"variance upon 2-month testing data:\",variance2)\n",
    "print(\"MAPE upon 2-month testing data:\",mape2)\n",
    "\n",
    "reg_training18=linear_model.BayesianRidge(n_iter=350, tol=0.001, alpha_1=1e-06, alpha_2=1e-06, lambda_1=1e-06, lambda_2=1e-06).fit(training18_features,training18_label)\n",
    "prediction_testing3=reg_training18.predict(testing3_features)\n",
    "n3=testing3_label.shape[0]\n",
    "label3=testing3_label\n",
    "prediction3=prediction_testing3\n",
    "mape3=mape(n3,label3,prediction3)\n",
    "variance3=variance(n3,label3,prediction3)\n",
    "print(\"variance upon 3-month testing data:\",variance3)\n",
    "print(\"MAPE upon 3-month testing data:\",mape3)\n",
    "\n",
    "reg_training16=linear_model.BayesianRidge(n_iter=350, tol=0.001, alpha_1=1e-06, alpha_2=1e-06, lambda_1=1e-06, lambda_2=1e-06).fit(training16_features,training16_label)\n",
    "prediction_testing4=reg_training16.predict(testing4_features)\n",
    "n4=testing4_label.shape[0]\n",
    "label4=testing4_label\n",
    "prediction4=prediction_testing4\n",
    "mape4=mape(n4,label4,prediction4)\n",
    "variance4=variance(n4,label4,prediction4)\n",
    "print(\"variance upon 4-month testing data:\",variance4)\n",
    "print(\"MAPE upon 4-month testing data:\",mape4)\n",
    "\n",
    "reg_training14=linear_model.BayesianRidge(n_iter=350, tol=0.001, alpha_1=1e-06, alpha_2=1e-06, lambda_1=1e-06, lambda_2=1e-06).fit(training14_features,training14_label)\n",
    "prediction_testing5=reg_training14.predict(testing5_features)\n",
    "n5=testing5_label.shape[0]\n",
    "label5=testing5_label\n",
    "prediction5=prediction_testing5\n",
    "mape5=mape(n5,label5,prediction5)\n",
    "variance5=variance(n5,label5,prediction5)\n",
    "print(\"variance upon 5-month testing data:\",variance5)\n",
    "print(\"MAPE upon 5-month testing data:\",mape5)\n",
    "\n",
    "reg_training12=linear_model.BayesianRidge(n_iter=300, tol=0.001, alpha_1=1e-06, alpha_2=1e-06, lambda_1=1e-06, lambda_2=1e-06).fit(training12_features,training12_label)\n",
    "prediction_testing6=reg_training12.predict(testing6_features)\n",
    "n6=testing6_label.shape[0]\n",
    "label6=testing6_label\n",
    "prediction6=prediction_testing6\n",
    "mape6=mape(n6,label6,prediction6)\n",
    "variance6=variance(n6,label6,prediction6)\n",
    "print(\"variance upon 6-month testing data:\",variance6)\n",
    "print(\"MAPE upon 6-month testing data:\",mape6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shans\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDRegressor'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance upon 1-month testing data: 0.012967673410166398\n",
      "MAPE upon 1-month testing data: 0.1949027571202725\n",
      "variance upon 2-month testing data: 0.009475180021756478\n",
      "MAPE upon 2-month testing data: 0.3909277200372649\n",
      "variance upon 3-month testing data: 0.016347936577992796\n",
      "MAPE upon 3-month testing data: 0.21568624151344065\n",
      "variance upon 4-month testing data: 0.019134829413251297\n",
      "MAPE upon 4-month testing data: 0.2916399790889785\n",
      "variance upon 5-month testing data: 0.02166098610697339\n",
      "MAPE upon 5-month testing data: 0.22287615424878993\n",
      "variance upon 6-month testing data: 0.01764572575985696\n",
      "MAPE upon 6-month testing data: 0.20874634425569683\n"
     ]
    }
   ],
   "source": [
    "#SGDRegressor from sklearn.linear_model import LinearRegression def mean_absolute_percentage_error(y_true, y_pred):\n",
    "from  sklearn import linear_model\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    #y_true, y_pred = check_arrays(y_true, y_pred)\n",
    "    return np.abs((y_true - y_pred) / y_true)\n",
    "def mape(n,label,prediction): \n",
    "    j=0\n",
    "    for i in range(0,n,1):\n",
    "        mapen=mean_absolute_percentage_error(label[i],prediction[i])\n",
    "        j=j+mapen\n",
    "    return j/n\n",
    "def variance(n,label,prediction): \n",
    "    j=0\n",
    "    transfer_power = []\n",
    "    for i in range(0,n,1):\n",
    "        mapen=mean_absolute_percentage_error(label[i],prediction[i])\n",
    "        transfer_power.append(mapen)\n",
    "    return np.var(transfer_power)\n",
    "reg_training22=linear_model.SGDRegressor(loss='squared_loss',penalty='l1',alpha=0.0005, learning_rate='invscaling', l1_ratio=0.15,eta0=0.03,power_t=0.25).fit(training22_features,training22_label)\n",
    "prediction_testing1=reg_training22.predict(testing1_features)\n",
    "n1=testing1_label.shape[0]\n",
    "label1=testing1_label\n",
    "prediction1=prediction_testing1\n",
    "mape1=mape(n1,label1,prediction1)\n",
    "variance1=variance(n1,label1,prediction1)\n",
    "print(\"variance upon 1-month testing data:\",variance1)\n",
    "print(\"MAPE upon 1-month testing data:\",mape1)\n",
    "reg_training20=linear_model.SGDRegressor(loss='squared_loss',penalty='l1',alpha=0.0001, learning_rate='invscaling', l1_ratio=0.12,eta0=0.01,power_t=0.25).fit(training20_features,training20_label)\n",
    "prediction_testing2=reg_training20.predict(testing2_features)\n",
    "n2=testing2_label.shape[0]\n",
    "label2=testing2_label\n",
    "prediction2=prediction_testing2\n",
    "mape2=mape(n2,label2,prediction2)\n",
    "variance2=variance(n2,label2,prediction2)\n",
    "print(\"variance upon 2-month testing data:\",variance2)\n",
    "print(\"MAPE upon 2-month testing data:\",mape2)\n",
    "reg_training18=linear_model.SGDRegressor(loss='squared_loss',penalty='l2',alpha=0.0001, learning_rate='invscaling', l1_ratio=0.10,eta0=0.01,power_t=0.25).fit(training18_features,training18_label)\n",
    "prediction_testing3=reg_training18.predict(testing3_features)\n",
    "n3=testing3_label.shape[0]\n",
    "label3=testing3_label\n",
    "prediction3=prediction_testing3\n",
    "mape3=mape(n3,label3,prediction3)\n",
    "variance3=variance(n3,label3,prediction3)\n",
    "print(\"variance upon 3-month testing data:\",variance3)\n",
    "print(\"MAPE upon 3-month testing data:\",mape3)\n",
    "reg_training16=linear_model.SGDRegressor(loss='squared_loss',penalty='l1',alpha=0.0001, learning_rate='invscaling', l1_ratio=0.12,eta0=0.01,power_t=0.25).fit(training16_features,training16_label)\n",
    "prediction_testing4=reg_training16.predict(testing4_features)\n",
    "n4=testing4_label.shape[0]\n",
    "label4=testing4_label\n",
    "prediction4=prediction_testing4\n",
    "mape4=mape(n4,label4,prediction4)\n",
    "variance4=variance(n4,label4,prediction4)\n",
    "print(\"variance upon 4-month testing data:\",variance4)\n",
    "print(\"MAPE upon 4-month testing data:\",mape4)\n",
    "reg_training14=linear_model.SGDRegressor(loss='squared_loss',penalty='l1',alpha=0.0001, learning_rate='invscaling', l1_ratio=0.10,eta0=0.01,power_t=0.25).fit(training14_features,training14_label)\n",
    "prediction_testing5=reg_training14.predict(testing5_features)\n",
    "n5=testing5_label.shape[0]\n",
    "label5=testing5_label\n",
    "prediction5=prediction_testing5\n",
    "mape5=mape(n5,label5,prediction5)\n",
    "variance5=variance(n5,label5,prediction5)\n",
    "print(\"variance upon 5-month testing data:\",variance5)\n",
    "print(\"MAPE upon 5-month testing data:\",mape5)\n",
    "reg_training12=linear_model.SGDRegressor(loss='squared_loss',penalty='l1',alpha=0.0001, learning_rate='invscaling', l1_ratio=0.12,eta0=0.01,power_t=0.25).fit(training12_features,training12_label) \n",
    "prediction_testing6=reg_training12.predict(testing6_features) \n",
    "n6=testing6_label.shape[0] \n",
    "label6=testing6_label \n",
    "prediction6=prediction_testing6 \n",
    "mape6=mape(n6,label6,prediction6) \n",
    "variance6=variance(n6,label6,prediction6) \n",
    "print(\"variance upon 6-month testing data:\",variance6) \n",
    "print(\"MAPE upon 6-month testing data:\",mape6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance upon 1-month testing data: 0.008954249421009001\n",
      "MAPE upon 1-month testing data: 0.130539823006554\n",
      "variance upon 2-month testing data: 0.013813389419052097\n",
      "MAPE upon 2-month testing data: 0.4275382808941306\n",
      "variance upon 3-month testing data: 0.02083041285001108\n",
      "MAPE upon 3-month testing data: 0.17559287472542404\n",
      "variance upon 4-month testing data: 0.026412035915755916\n",
      "MAPE upon 4-month testing data: 0.3362598617350086\n",
      "variance upon 5-month testing data: 0.021615972004839584\n",
      "MAPE upon 5-month testing data: 0.18075177534007048\n",
      "variance upon 6-month testing data: 0.01883094290135005\n",
      "MAPE upon 6-month testing data: 0.19572411480672253\n"
     ]
    }
   ],
   "source": [
    "#Nearest Neighbors Regression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    #y_true, y_pred = check_arrays(y_true, y_pred)\n",
    "    return np.abs((y_true - y_pred) / y_true)\n",
    "def mape(n,label,prediction): \n",
    "    j=0\n",
    "    for i in range(0,n,1):\n",
    "        mapen=mean_absolute_percentage_error(label[i],prediction[i])\n",
    "        j=j+mapen\n",
    "    return j/n\n",
    "def variance(n,label,prediction): \n",
    "    j=0\n",
    "    transfer_power = []\n",
    "    for i in range(0,n,1):\n",
    "        mapen=mean_absolute_percentage_error(label[i],prediction[i])\n",
    "        transfer_power.append(mapen)\n",
    "    return np.var(transfer_power)\n",
    "\n",
    "reg_training22=KNeighborsRegressor(n_neighbors=10, leaf_size=30, p=2).fit(training22_features,training22_label)\n",
    "prediction_testing1=reg_training22.predict(testing1_features)\n",
    "n1=testing1_label.shape[0]\n",
    "label1=testing1_label\n",
    "prediction1=prediction_testing1\n",
    "mape1=mape(n1,label1,prediction1)\n",
    "variance1=variance(n1,label1,prediction1)\n",
    "print(\"variance upon 1-month testing data:\",variance1)\n",
    "print(\"MAPE upon 1-month testing data:\",mape1)\n",
    "\n",
    "reg_training20=KNeighborsRegressor(n_neighbors=5, leaf_size=30, p=2).fit(training20_features,training20_label)\n",
    "prediction_testing2=reg_training20.predict(testing2_features)\n",
    "n2=testing2_label.shape[0]\n",
    "label2=testing2_label\n",
    "prediction2=prediction_testing2\n",
    "mape2=mape(n2,label2,prediction2)\n",
    "variance2=variance(n2,label2,prediction2)\n",
    "print(\"variance upon 2-month testing data:\",variance2)\n",
    "print(\"MAPE upon 2-month testing data:\",mape2)\n",
    "\n",
    "reg_training18=KNeighborsRegressor(n_neighbors=10, leaf_size=30, p=2).fit(training18_features,training18_label)\n",
    "prediction_testing3=reg_training18.predict(testing3_features)\n",
    "n3=testing3_label.shape[0]\n",
    "label3=testing3_label\n",
    "prediction3=prediction_testing3\n",
    "mape3=mape(n3,label3,prediction3)\n",
    "variance3=variance(n3,label3,prediction3)\n",
    "print(\"variance upon 3-month testing data:\",variance3)\n",
    "print(\"MAPE upon 3-month testing data:\",mape3)\n",
    "\n",
    "reg_training16=KNeighborsRegressor(n_neighbors=10, leaf_size=30, p=2).fit(training16_features,training16_label)\n",
    "prediction_testing4=reg_training16.predict(testing4_features)\n",
    "n4=testing4_label.shape[0]\n",
    "label4=testing4_label\n",
    "prediction4=prediction_testing4\n",
    "mape4=mape(n4,label4,prediction4)\n",
    "variance4=variance(n4,label4,prediction4)\n",
    "print(\"variance upon 4-month testing data:\",variance4)\n",
    "print(\"MAPE upon 4-month testing data:\",mape4)\n",
    "\n",
    "reg_training14=KNeighborsRegressor(n_neighbors=10, leaf_size=30, p=2).fit(training14_features,training14_label)\n",
    "prediction_testing5=reg_training14.predict(testing5_features)\n",
    "n5=testing5_label.shape[0]\n",
    "label5=testing5_label\n",
    "prediction5=prediction_testing5\n",
    "mape5=mape(n5,label5,prediction5)\n",
    "variance5=variance(n5,label5,prediction5)\n",
    "print(\"variance upon 5-month testing data:\",variance5)\n",
    "print(\"MAPE upon 5-month testing data:\",mape5)\n",
    "\n",
    "reg_training12=KNeighborsRegressor(n_neighbors=10, leaf_size=30, p=2).fit(training12_features,training12_label)\n",
    "prediction_testing6=reg_training12.predict(testing6_features)\n",
    "n6=testing6_label.shape[0]\n",
    "label6=testing6_label\n",
    "prediction6=prediction_testing6\n",
    "mape6=mape(n6,label6,prediction6)\n",
    "variance6=variance(n6,label6,prediction6)\n",
    "print(\"variance upon 6-month testing data:\",variance6)\n",
    "print(\"MAPE upon 6-month testing data:\",mape6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance upon 1-month testing data: 0.010735360313839966\n",
      "MAPE upon 1-month testing data: 0.13063205324264682\n",
      "variance upon 2-month testing data: 0.015319077665310684\n",
      "MAPE upon 2-month testing data: 0.4250412186608995\n",
      "variance upon 3-month testing data: 0.019928111132074693\n",
      "MAPE upon 3-month testing data: 0.17231293053393137\n",
      "variance upon 4-month testing data: 0.025038702132571772\n",
      "MAPE upon 4-month testing data: 0.3294816368650593\n",
      "variance upon 5-month testing data: 0.02009685828884945\n",
      "MAPE upon 5-month testing data: 0.17571133333064576\n",
      "variance upon 6-month testing data: 0.01771525656189209\n",
      "MAPE upon 6-month testing data: 0.19253478725664003\n"
     ]
    }
   ],
   "source": [
    "#decision tree\n",
    "from sklearn import tree\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    #y_true, y_pred = check_arrays(y_true, y_pred)\n",
    "    return np.abs((y_true - y_pred) / y_true)\n",
    "def mape(n,label,prediction): \n",
    "    j=0\n",
    "    for i in range(0,n,1):\n",
    "        mapen=mean_absolute_percentage_error(label[i],prediction[i])\n",
    "        j=j+mapen\n",
    "    return j/n\n",
    "def variance(n,label,prediction): \n",
    "    j=0\n",
    "    transfer_power = []\n",
    "    for i in range(0,n,1):\n",
    "        mapen=mean_absolute_percentage_error(label[i],prediction[i])\n",
    "        transfer_power.append(mapen)\n",
    "    return np.var(transfer_power)\n",
    "#\n",
    "reg_training22=tree.DecisionTreeRegressor(min_samples_split =4,min_samples_leaf = 1).fit(training22_features,training22_label)\n",
    "prediction_testing1=reg_training22.predict(testing1_features)\n",
    "n1=testing1_label.shape[0]\n",
    "label1=testing1_label\n",
    "prediction1=prediction_testing1\n",
    "mape1=mape(n1,label1,prediction1)\n",
    "variance1=variance(n1,label1,prediction1)\n",
    "print(\"variance upon 1-month testing data:\",variance1)\n",
    "print(\"MAPE upon 1-month testing data:\",mape1)\n",
    "\n",
    "reg_training20=tree.DecisionTreeRegressor(min_samples_split =6,min_samples_leaf = 1).fit(training20_features,training20_label)\n",
    "prediction_testing2=reg_training20.predict(testing2_features)\n",
    "n2=testing2_label.shape[0]\n",
    "label2=testing2_label\n",
    "prediction2=prediction_testing2\n",
    "mape2=mape(n2,label2,prediction2)\n",
    "variance2=variance(n2,label2,prediction2)\n",
    "print(\"variance upon 2-month testing data:\",variance2)\n",
    "print(\"MAPE upon 2-month testing data:\",mape2)\n",
    "\n",
    "reg_training18=tree.DecisionTreeRegressor(min_samples_split =500,min_samples_leaf = 1).fit(training18_features,training18_label)\n",
    "prediction_testing3=reg_training18.predict(testing3_features)\n",
    "n3=testing3_label.shape[0]\n",
    "label3=testing3_label\n",
    "prediction3=prediction_testing3\n",
    "mape3=mape(n3,label3,prediction3)\n",
    "variance3=variance(n3,label3,prediction3)\n",
    "print(\"variance upon 3-month testing data:\",variance3)\n",
    "print(\"MAPE upon 3-month testing data:\",mape3)\n",
    "\n",
    "reg_training16=tree.DecisionTreeRegressor(min_samples_split =400,min_samples_leaf = 1).fit(training16_features,training16_label)\n",
    "prediction_testing4=reg_training16.predict(testing4_features)\n",
    "n4=testing4_label.shape[0]\n",
    "label4=testing4_label\n",
    "prediction4=prediction_testing4\n",
    "mape4=mape(n4,label4,prediction4)\n",
    "variance4=variance(n4,label4,prediction4)\n",
    "print(\"variance upon 4-month testing data:\",variance4)\n",
    "print(\"MAPE upon 4-month testing data:\",mape4)\n",
    "\n",
    "reg_training14=tree.DecisionTreeRegressor(min_samples_split =500,min_samples_leaf = 1).fit(training14_features,training14_label)\n",
    "prediction_testing5=reg_training14.predict(testing5_features)\n",
    "n5=testing5_label.shape[0]\n",
    "label5=testing5_label\n",
    "prediction5=prediction_testing5\n",
    "mape5=mape(n5,label5,prediction5)\n",
    "variance5=variance(n5,label5,prediction5)\n",
    "print(\"variance upon 5-month testing data:\",variance5)\n",
    "print(\"MAPE upon 5-month testing data:\",mape5)\n",
    "\n",
    "reg_training12=tree.DecisionTreeRegressor(min_samples_split =400,min_samples_leaf = 1).fit(training12_features,training12_label)\n",
    "prediction_testing6=reg_training12.predict(testing6_features)\n",
    "n6=testing6_label.shape[0]\n",
    "label6=testing6_label\n",
    "prediction6=prediction_testing6\n",
    "mape6=mape(n6,label6,prediction6)\n",
    "variance6=variance(n6,label6,prediction6)\n",
    "print(\"variance upon 6-month testing data:\",variance6)\n",
    "print(\"MAPE upon 6-month testing data:\",mape6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shans\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance upon 1-month testing data: 0.011580762739783772\n",
      "MAPE upon 1-month testing data: 0.16421979258968877\n",
      "variance upon 2-month testing data: 0.009937808599654627\n",
      "MAPE upon 2-month testing data: 0.38827484954856184\n",
      "variance upon 3-month testing data: 0.016275467484145406\n",
      "MAPE upon 3-month testing data: 0.21153899578403046\n",
      "variance upon 4-month testing data: 0.019158234000775032\n",
      "MAPE upon 4-month testing data: 0.29721764649478777\n",
      "variance upon 5-month testing data: 0.021939168598703807\n",
      "MAPE upon 5-month testing data: 0.21644467793986835\n",
      "variance upon 6-month testing data: 0.016780202065954538\n",
      "MAPE upon 6-month testing data: 0.20521937494511638\n"
     ]
    }
   ],
   "source": [
    "#MLPRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    #y_true, y_pred = check_arrays(y_true, y_pred)\n",
    "    return np.abs((y_true - y_pred) / y_true)\n",
    "def mape(n,label,prediction): \n",
    "    j=0\n",
    "    for i in range(0,n,1):\n",
    "        mapen=mean_absolute_percentage_error(label[i],prediction[i])\n",
    "        j=j+mapen\n",
    "    return j/n\n",
    "def variance(n,label,prediction): \n",
    "    j=0\n",
    "    transfer_power = []\n",
    "    for i in range(0,n,1):\n",
    "        mapen=mean_absolute_percentage_error(label[i],prediction[i])\n",
    "        transfer_power.append(mapen)\n",
    "    return np.var(transfer_power)\n",
    "#\n",
    "reg_training22=MLPRegressor(hidden_layer_sizes=(100,), activation='tanh', alpha=0.0001).fit(training22_features,training22_label)\n",
    "prediction_testing1=reg_training22.predict(testing1_features)\n",
    "n1=testing1_label.shape[0]\n",
    "label1=testing1_label\n",
    "prediction1=prediction_testing1\n",
    "mape1=mape(n1,label1,prediction1)\n",
    "variance1=variance(n1,label1,prediction1)\n",
    "print(\"variance upon 1-month testing data:\",variance1)\n",
    "print(\"MAPE upon 1-month testing data:\",mape1)\n",
    "\n",
    "reg_training20=MLPRegressor(hidden_layer_sizes=(100,), activation='relu', alpha=0.0001).fit(training20_features,training20_label)\n",
    "prediction_testing2=reg_training20.predict(testing2_features)\n",
    "n2=testing2_label.shape[0]\n",
    "label2=testing2_label\n",
    "prediction2=prediction_testing2\n",
    "mape2=mape(n2,label2,prediction2)\n",
    "variance2=variance(n2,label2,prediction2)\n",
    "print(\"variance upon 2-month testing data:\",variance2)\n",
    "print(\"MAPE upon 2-month testing data:\",mape2)\n",
    "\n",
    "reg_training18=MLPRegressor(hidden_layer_sizes=(100,), activation='relu', alpha=0.0005).fit(training18_features,training18_label)\n",
    "prediction_testing3=reg_training18.predict(testing3_features)\n",
    "n3=testing3_label.shape[0]\n",
    "label3=testing3_label\n",
    "prediction3=prediction_testing3\n",
    "mape3=mape(n3,label3,prediction3)\n",
    "variance3=variance(n3,label3,prediction3)\n",
    "print(\"variance upon 3-month testing data:\",variance3)\n",
    "print(\"MAPE upon 3-month testing data:\",mape3)\n",
    "\n",
    "reg_training16=MLPRegressor(hidden_layer_sizes=(100,), activation='relu', alpha=0.0001).fit(training16_features,training16_label)\n",
    "prediction_testing4=reg_training16.predict(testing4_features)\n",
    "n4=testing4_label.shape[0]\n",
    "label4=testing4_label\n",
    "prediction4=prediction_testing4\n",
    "mape4=mape(n4,label4,prediction4)\n",
    "variance4=variance(n4,label4,prediction4)\n",
    "print(\"variance upon 4-month testing data:\",variance4)\n",
    "print(\"MAPE upon 4-month testing data:\",mape4)\n",
    "\n",
    "reg_training14=MLPRegressor(hidden_layer_sizes=(100,), activation='relu', alpha=0.0001).fit(training14_features,training14_label)\n",
    "prediction_testing5=reg_training14.predict(testing5_features)\n",
    "n5=testing5_label.shape[0]\n",
    "label5=testing5_label\n",
    "prediction5=prediction_testing5\n",
    "mape5=mape(n5,label5,prediction5)\n",
    "variance5=variance(n5,label5,prediction5)\n",
    "print(\"variance upon 5-month testing data:\",variance5)\n",
    "print(\"MAPE upon 5-month testing data:\",mape5)\n",
    "\n",
    "reg_training12=MLPRegressor(hidden_layer_sizes=(100,), activation='relu', alpha=0.0001).fit(training12_features,training12_label)\n",
    "prediction_testing6=reg_training12.predict(testing6_features)\n",
    "n6=testing6_label.shape[0]\n",
    "label6=testing6_label\n",
    "prediction6=prediction_testing6\n",
    "mape6=mape(n6,label6,prediction6)\n",
    "variance6=variance(n6,label6,prediction6)\n",
    "print(\"variance upon 6-month testing data:\",variance6)\n",
    "print(\"MAPE upon 6-month testing data:\",mape6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of parameter combinations for Seasonal ARIMA...\n",
      "SARIMAX: (0, 0, 1) x (0, 0, 1, 12)\n",
      "SARIMAX: (0, 0, 1) x (0, 1, 0, 12)\n",
      "SARIMAX: (0, 1, 0) x (0, 1, 1, 12)\n",
      "SARIMAX: (0, 1, 0) x (1, 0, 0, 12)\n",
      "The smallest AIC is 134432.24329409853 for model SARIMAX(3, 1, 1)x(3, 1, 1, 12)\n"
     ]
    }
   ],
   "source": [
    "#Arima\n",
    "import warnings\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "# Load the data\n",
    "data = pd.read_csv('powerData2013.csv', engine='python', skipfooter=3)\n",
    "# A bit of pre-processing to make it nicer\n",
    "data['Day']=pd.to_datetime(data['Day'], format='%Y-%m-%d %H:%M:%S')\n",
    "data.set_index(['Day'], inplace=True)\n",
    "# Define the d and q parameters to take any value between 0 and 1\n",
    "q = d = range(0, 2)\n",
    "# Define the p parameters to take any value between 0 and 3\n",
    "p = range(0, 4)\n",
    "# Generate all different combinations of p, q and q triplets\n",
    "pdq = list(itertools.product(p, d, q))\n",
    "# Generate all different combinations of seasonal p, q and q triplets\n",
    "seasonal_pdq = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))]\n",
    "print('Examples of parameter combinations for Seasonal ARIMA...')\n",
    "print('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[1]))\n",
    "print('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[2]))\n",
    "print('SARIMAX: {} x {}'.format(pdq[2], seasonal_pdq[3]))\n",
    "print('SARIMAX: {} x {}'.format(pdq[2], seasonal_pdq[4]))\n",
    "train_data = data['2013/9/1 0:00:00':'2014/12/31 23:00:00']\n",
    "test_data = data['2015/5/1 0:00:00':'2015/8/31 23:00:00']\n",
    "warnings.filterwarnings(\"ignore\") # specify to ignore warning messages\n",
    "AIC = []\n",
    "SARIMAX_model = []\n",
    "for param in pdq:\n",
    "    for param_seasonal in seasonal_pdq:\n",
    "        try:\n",
    "            mod = sm.tsa.statespace.SARIMAX(train_data,\n",
    "                                            order=param,\n",
    "                                            seasonal_order=param_seasonal,\n",
    "                                            enforce_stationarity=False,\n",
    "                                            enforce_invertibility=False)\n",
    "            results = mod.fit()\n",
    "            print('SARIMAX{}x{} - AIC:{}'.format(param, param_seasonal, results.aic), end='\\r')\n",
    "            AIC.append(results.aic)\n",
    "            SARIMAX_model.append([param, param_seasonal])\n",
    "        except:\n",
    "            continue\n",
    "print('The smallest AIC is {} for model SARIMAX{}x{}'.format(min(AIC), SARIMAX_model[AIC.index(min(AIC))][0],SARIMAX_model[AIC.index(min(AIC))][1]))\n",
    "# Let's fit this model\n",
    "mod = sm.tsa.statespace.SARIMAX(train_data,\n",
    "                                order=SARIMAX_model[AIC.index(min(AIC))][0],\n",
    "                                seasonal_order=SARIMAX_model[AIC.index(min(AIC))][1],\n",
    "                                enforce_stationarity=False,\n",
    "                                enforce_invertibility=False)\n",
    "\n",
    "results = mod.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance: 0.01596036002392596\n",
      "MAPE: 0.27688452537291053\n"
     ]
    }
   ],
   "source": [
    "pred2 = results.get_forecast('2015/9/1')\n",
    "pred2_ci = pred2.conf_int()\n",
    "\n",
    "n=test_data.shape[0]\n",
    "#print(n)\n",
    "transfer_power = []\n",
    "j=0\n",
    "for i in range(0,n,1):\n",
    "    pre=pred2.predicted_mean['2015/5/1 0:00:00':'2015/8/31 23:00:00'][i]\n",
    "    real=test_data.loc[:,'power'][0]\n",
    "    mape=np.abs((real-pre)/real)\n",
    "    transfer_power.append(mape)\n",
    "    j=j+mape\n",
    "variance=np.var(transfer_power)\n",
    "mape=j/n\n",
    "print(\"variance:\",variance)\n",
    "print(\"MAPE:\",mape)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
